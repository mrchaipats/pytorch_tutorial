{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c974ae0",
   "metadata": {},
   "source": [
    "TorchScript is an intermediate representation of a PyTorch model that can be run in a high-performance environment such as C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bdf6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73862d8",
   "metadata": {},
   "source": [
    "A module consists of three main components:\n",
    "1. A constructor\n",
    "2. A set of Parameters and sub-Modules\n",
    "3. A forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbcf9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.6459, 0.7476, 0.7187, 0.7204],\n",
      "        [0.8514, 0.8134, 0.7587, 0.7128],\n",
      "        [0.7636, 0.8745, 0.5874, 0.7938]]), tensor([[0.6459, 0.7476, 0.7187, 0.7204],\n",
      "        [0.8514, 0.8134, 0.7587, 0.7128],\n",
      "        [0.7636, 0.8745, 0.5874, 0.7938]]))\n"
     ]
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(x + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c019fb",
   "metadata": {},
   "source": [
    "### Building a hierarchy of Modules\n",
    "\n",
    "By using a `torch.nn.Linear` module within the `MyCell` module, we are building a hierarchy of `Module`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228b7f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[-0.4871, -0.0639,  0.7874, -0.0934],\n",
      "        [ 0.5208, -0.5190,  0.7104,  0.2067],\n",
      "        [ 0.5020, -0.3728,  0.1434, -0.0503]], grad_fn=<TanhBackward0>), tensor([[-0.4871, -0.0639,  0.7874, -0.0934],\n",
      "        [ 0.5208, -0.5190,  0.7104,  0.2067],\n",
      "        [ 0.5020, -0.3728,  0.1434, -0.0503]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9c3cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (dg): MyDecisionGate()\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[ 0.2657,  0.4078,  0.4647,  0.6438],\n",
      "        [ 0.8248,  0.1254,  0.3423,  0.9201],\n",
      "        [ 0.8192,  0.2591, -0.5026,  0.9065]], grad_fn=<TanhBackward0>), tensor([[ 0.2657,  0.4078,  0.4647,  0.6438],\n",
      "        [ 0.8248,  0.1254,  0.3423,  0.9201],\n",
      "        [ 0.8192,  0.2591, -0.5026,  0.9065]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        # utilizing control flow (if statement)\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940cb42",
   "metadata": {},
   "source": [
    "### Gradient tape\n",
    "\n",
    "PyTorch use a gradient tape to record operations as they occur, and replay them backwards in computing derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a9bde",
   "metadata": {},
   "source": [
    "### Basics of TorchScript\n",
    "\n",
    "TorchScript provides tools to capture the definition of your model using `tracing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ecb8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  original_name=MyCell\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1199,  0.4323,  0.4247,  0.3825],\n",
       "         [-0.0318,  0.4097,  0.8126,  0.8418],\n",
       "         [-0.6526,  0.7871,  0.8530,  0.5522]], grad_fn=<TanhBackward0>),\n",
       " tensor([[ 0.1199,  0.4323,  0.4247,  0.3825],\n",
       "         [-0.0318,  0.4097,  0.8126,  0.8418],\n",
       "         [-0.6526,  0.7871,  0.8530,  0.5522]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell)\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33802fab",
   "metadata": {},
   "source": [
    "TorchScript records its definitions in an Intermediate Representation (IR), commonly referred to in Deep learning as a `graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23de9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.MyCell,\n",
      "      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n",
      "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
      "  %linear : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
      "  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n",
      "  %11 : int = prim::Constant[value=1]() # /var/folders/yh/yw23prz55635x1mx37sy_kp40000gn/T/ipykernel_6336/4016154612.py:7:0\n",
      "  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%20, %h, %11) # /var/folders/yh/yw23prz55635x1mx37sy_kp40000gn/T/ipykernel_6336/4016154612.py:7:0\n",
      "  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%12) # /var/folders/yh/yw23prz55635x1mx37sy_kp40000gn/T/ipykernel_6336/4016154612.py:7:0\n",
      "  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%13, %13)\n",
      "  return (%14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd315376",
   "metadata": {},
   "source": [
    "`graph` is hard to understand. Instead, we can use the `.code` property to give a Python-syntax interpretation of the low-level `graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59492681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e253ee",
   "metadata": {},
   "source": [
    "### Benefits of using TorchScript:\n",
    "1. TorchScript can be invoked in its own interpreter that does not acquire the Global Interpreter Lock (GIL), and so many requests can be processed on the same instance simultaneously.\n",
    "\n",
    "2. This format allows us to save the whole model to disk and load it into another environment, such as in a server written in a language other than Python.\n",
    "\n",
    "3. TorchScript gives us a representation in which we can do compiler optimization.\n",
    "\n",
    "4. TorchScript allows us to interface with many backend/device runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea93c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.1199,  0.4323,  0.4247,  0.3825],\n",
      "        [-0.0318,  0.4097,  0.8126,  0.8418],\n",
      "        [-0.6526,  0.7871,  0.8530,  0.5522]], grad_fn=<TanhBackward0>), tensor([[ 0.1199,  0.4323,  0.4247,  0.3825],\n",
      "        [-0.0318,  0.4097,  0.8126,  0.8418],\n",
      "        [-0.6526,  0.7871,  0.8530,  0.5522]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[ 0.1199,  0.4323,  0.4247,  0.3825],\n",
      "        [-0.0318,  0.4097,  0.8126,  0.8418],\n",
      "        [-0.6526,  0.7871,  0.8530,  0.5522]], grad_fn=<TanhBackward0>), tensor([[ 0.1199,  0.4323,  0.4247,  0.3825],\n",
      "        [-0.0318,  0.4097,  0.8126,  0.8418],\n",
      "        [-0.6526,  0.7871,  0.8530,  0.5522]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# verify that traced cell produces the same results as the Python module\n",
    "print(my_cell(x, h))\n",
    "print(traced_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388bd4c",
   "metadata": {},
   "source": [
    "### Script compiler\n",
    "\n",
    "Tracing does not include `control flows` such as `if-else statements` and `for-loop`\n",
    "\n",
    "Use `script compiler` to analyze Python source code to transform it into TorchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc67fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> NoneType:\n",
      "  return None\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = (linear).forward(x, )\n",
      "  _1 = (dg).forward(_0, )\n",
      "  _2 = torch.tanh(torch.add(_0, h))\n",
      "  return (_2, _2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/yw23prz55635x1mx37sy_kp40000gn/T/ipykernel_6336/54719284.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "        \n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "\n",
    "print(traced_cell.dg.code)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d6598",
   "metadata": {},
   "source": [
    "Use `script compiler` to convert `MyDecisionGate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5515de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "\n",
    "my_cell = MyCell(scripted_gate)\n",
    "scripted_cell = torch.jit.script(my_cell)\n",
    "\n",
    "print(scripted_gate.code)\n",
    "print(scripted_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a9e130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.8196e-01,  7.5139e-01,  6.2731e-01,  8.3418e-01],\n",
       "         [ 8.4364e-04,  6.2280e-01,  6.5460e-01,  8.2321e-01],\n",
       "         [-3.1970e-01,  6.8387e-01,  8.3628e-01,  8.7024e-01]],\n",
       "        grad_fn=<TanhBackward0>),\n",
       " tensor([[-3.8196e-01,  7.5139e-01,  6.2731e-01,  8.3418e-01],\n",
       "         [ 8.4364e-04,  6.2280e-01,  6.5460e-01,  8.2321e-01],\n",
       "         [-3.1970e-01,  6.8387e-01,  8.3628e-01,  8.7024e-01]],\n",
       "        grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the TorchScript\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35eafa",
   "metadata": {},
   "source": [
    "### Mixing Scripting and Tracing\n",
    "\n",
    "Scripting can be composed with tracing as the following two cases:\n",
    "- `torch.jit.script` will inline the code for a traced module\n",
    "- `torch.jit.trace` will inline the code for a scripted module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2836885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  h = torch.zeros([3, 4])\n",
      "  y = torch.zeros([3, 4])\n",
      "  y0 = y\n",
      "  h0 = h\n",
      "  for i in range(torch.size(xs, 0)):\n",
      "    cell = self.cell\n",
      "    _0 = (cell).forward(torch.select(xs, 0, i), h0, )\n",
      "    y1, h1, = _0\n",
      "    y0, h0 = y1, h1\n",
      "  return (y0, h0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first case\n",
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCell(scripted_gate), (x, h))\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "        return y, h\n",
    "\n",
    "rnn_loop = torch.jit.script(MyRNNLoop())\n",
    "print(rnn_loop.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a30e3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# second case\n",
    "class WrapRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WrapRNN, self).__init__()\n",
    "        self.loop = torch.jit.script(MyRNNLoop())\n",
    "\n",
    "    def forward(self, xs):\n",
    "        y, h = self.loop(xs)\n",
    "        return torch.relu(y)\n",
    "    \n",
    "traced = torch.jit.trace(\n",
    "    WrapRNN(),\n",
    "    (torch.rand(10, 3, 4))\n",
    ")\n",
    "\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df4731",
   "metadata": {},
   "source": [
    "### Saving and Loading models\n",
    "\n",
    "The TorchScript format includes code, parameters, attributes, and debug information. It can be loaded into an entirely separate process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2834193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=WrapRNN\n",
      "  (loop): RecursiveScriptModule(\n",
      "    original_name=MyRNNLoop\n",
      "    (cell): RecursiveScriptModule(\n",
      "      original_name=MyCell\n",
      "      (dg): RecursiveScriptModule(original_name=MyDecisionGate)\n",
      "      (linear): RecursiveScriptModule(original_name=Linear)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traced.save('wrapped_rnn.pt')\n",
    "\n",
    "loaded = torch.jit.load('wrapped_rnn.pt')\n",
    "\n",
    "print(loaded)\n",
    "print(loaded.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247b960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
